import asyncio
import os
import logging
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from aiogram.types import FSInputFile, InlineKeyboardMarkup, InlineKeyboardButton
from deep_translator import GoogleTranslator
from gtts import gTTS
import speech_recognition as sr
from pydub import AudioSegment

# --- Ğ¢ĞĞĞ—Ğ˜ĞœĞĞ¢ ---
TOKEN = '8560757080:AAFXJLy71LZTPKMmCiscpe1mWKmj3lC-hDE'

logging.basicConfig(level=logging.INFO)
bot = Bot(token=TOKEN)
dp = Dispatcher()
recognizer = sr.Recognizer()

# ĞĞ¸Ğ³Ğ¾Ò³ Ğ´Ğ¾ÑˆÑ‚Ğ°Ğ½Ğ¸ Ò³Ğ¾Ğ»Ğ°Ñ‚Ğ¸ ĞºĞ¾Ñ€Ğ±Ğ°Ñ€ (Ğ±Ğ¾ Ğ½Ğ¾Ğ±Ğ°Ñ‘Ğ½Ó£ Chain Translation)
user_modes = {}

def get_keyboard():
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="ğŸ”— TG â¡ï¸ RU â¡ï¸ EN (Ğ—Ğ°Ğ½Ò·Ğ¸Ñ€Ğ°Ğ²Ó£)", callback_data="chain_tg_ru_en")],
        [InlineKeyboardButton(text="ğŸ‡¹ğŸ‡¯ Ğ¢Ğ¾Ò·Ğ¸ĞºÓ£ â¡ï¸ ğŸ‡¬ğŸ‡§ English", callback_data="tg_en")],
        [InlineKeyboardButton(text="ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹ â¡ï¸ ğŸ‡¬ğŸ‡§ English", callback_data="ru_en")],
        [InlineKeyboardButton(text="ğŸ‡¬ğŸ‡§ English â¡ï¸ ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹", callback_data="en_ru")]
    ])

@dp.message(Command("start"))
async def start(message: types.Message):
    user_modes[message.from_user.id] = 'chain_tg_ru_en'
    await message.answer(
        "Ğ¡Ğ°Ğ»Ğ¾Ğ¼! ĞœĞ°Ğ½ Ğ±Ğ¾Ñ‚Ğ¸ Ñ‚Ğ°Ñ€Ò·ÑƒĞ¼Ğ¾Ğ½Ğ¸ Ğ°Ò›Ğ»Ğ½Ğ¾Ğº. \n"
        "Ò²Ğ¾Ğ»Ğ°Ñ‚Ğ¸ **Ğ—Ğ°Ğ½Ò·Ğ¸Ñ€Ğ°Ğ²Ó£ (TG->RU->EN)** Ñ„Ğ°ÑŠĞ¾Ğ» Ğ°ÑÑ‚. ĞĞ²Ğ¾Ğ· Ñ„Ğ¸Ñ€Ğ¸ÑÑ‚ĞµĞ´!", 
        reply_markup=get_keyboard()
    )

@dp.callback_query(F.data.contains("_"))
async def set_mode(callback: types.CallbackQuery):
    user_modes[callback.from_user.id] = callback.data
    await callback.message.answer(f"âœ… Ò²Ğ¾Ğ»Ğ°Ñ‚Ğ¸ Ğ½Ğ°Ğ² Ğ¸Ğ½Ñ‚Ğ¸Ñ…Ğ¾Ğ± ÑˆÑƒĞ´: {callback.data}")
    await callback.answer()

@dp.message(F.voice)
async def handle_voice(message: types.Message):
    mode = user_modes.get(message.from_user.id, 'chain_tg_ru_en')
    
    sent_msg = await message.answer("Ğ”Ğ°Ñ€ Ò³Ğ¾Ğ»Ğ¸ ĞºĞ¾Ñ€ĞºĞ°Ñ€Ğ´... ğŸ”„")
    
    ogg_path = f"v_{message.from_user.id}.ogg"
    wav_path = f"v_{message.from_user.id}.wav"
    
    await bot.download_file((await bot.get_file(message.voice.file_id)).file_path, ogg_path)

    try:
        # 1. Ğ¢Ğ°Ğ±Ğ´Ğ¸Ğ» Ğ±Ğ° WAV (FFmpeg Ğ´Ğ°Ñ€ ÑĞµÑ€Ğ²ĞµÑ€ Ğ»Ğ¾Ğ·Ğ¸Ğ¼ Ğ°ÑÑ‚)
        AudioSegment.from_file(ogg_path).export(wav_path, format="wav")
        

        with sr.AudioFile(wav_path) as source:
            recognizer.adjust_for_ambient_noise(source)
            audio_data = recognizer.record(source)
            
            # ĞĞ³Ğ°Ñ€ Ò³Ğ¾Ğ»Ğ°Ñ‚ Ğ·Ğ°Ğ½Ò·Ğ¸Ñ€Ğ°Ğ²Ó£ Ğ±Ğ¾ÑˆĞ°Ğ´
            if mode == 'chain_tg_ru_en':
                # Ğ¨Ğ¸Ğ½Ğ¾Ñ…Ñ‚Ğ°Ğ½Ğ¸ Ğ¾Ğ²Ğ¾Ğ· (Ğ¢Ğ¾Ò·Ğ¸ĞºÓ£)
                original_text = recognizer.recognize_google(audio_data, language='tg-TJ')
                
                # ÒšĞ°Ğ´Ğ°Ğ¼Ğ¸ 1: TG -> RU
                russian_text = GoogleTranslator(source='tg', target='ru').translate(original_text)
                
                # ÒšĞ°Ğ´Ğ°Ğ¼Ğ¸ 2: RU -> EN
                english_text = GoogleTranslator(source='ru', target='en').translate(russian_text)
                
                # Ğ¡Ğ¾Ñ…Ñ‚Ğ°Ğ½Ğ¸ Ğ¾Ğ²Ğ¾Ğ· (ĞĞ½Ğ³Ğ»Ğ¸ÑÓ£)
                res_path = f"res_{message.from_user.id}.mp3"
                gTTS(text=english_text, lang='en').save(res_path)
                
                result = (
                    f"ğŸ‡¹ğŸ‡¯ **Ğ¨ÑƒĞ¼Ğ¾ Ğ³ÑƒÑ„Ñ‚ĞµĞ´:** {original_text}\n"
                    f"ğŸ‡·ğŸ‡º **Ğ¢Ğ°Ñ€Ò·ÑƒĞ¼Ğ°Ğ¸ Ñ€ÑƒÑÓ£:** {russian_text}\n"
                    f"ğŸ‡¬ğŸ‡§ **Ğ¢Ğ°Ñ€Ò·ÑƒĞ¼Ğ°Ğ¸ Ğ°Ğ½Ğ³Ğ»Ğ¸ÑÓ£:** {english_text}"
                )
                await message.answer(result, parse_mode="Markdown")
                await message.answer_voice(FSInputFile(res_path))
                os.remove(res_path)
            
            else:
                # Ğ¢Ğ°Ñ€Ò·ÑƒĞ¼Ğ°Ğ¸ Ğ¼ÑƒÒ›Ğ°Ñ€Ñ€Ğ°Ñ€Ó£ (Ğ°Ğ³Ğ°Ñ€ Ñ‚ÑƒĞ³Ğ¼Ğ°Ò³Ğ¾Ğ¸ Ğ´Ğ¸Ğ³Ğ°Ñ€Ñ€Ğ¾ Ğ¿Ğ°Ñ…Ñˆ ĞºÑƒĞ½ĞµĞ´)
                src, dest = mode.split('_')
                stt_lang = 'tg-TJ' if src == 'tg' else 'ru-RU' if src == 'ru' else 'en-US'
                text = recognizer.recognize_google(audio_data, language=stt_lang)
                translated = GoogleTranslator(source=src, target=dest).translate(text)
                
                res_path = f"simple_{message.from_user.id}.mp3"
                gTTS(text=translated, lang=dest if dest in ['en', 'ru'] else 'ru').save(res_path)
                
                await message.answer(f"ğŸ¤ {text}\nğŸ“ {translated}")
                await message.answer_voice(FSInputFile(res_path))
                os.remove(res_path)

    except Exception as e:
        await message.answer(f"âŒ Ğ¥Ğ°Ñ‚Ğ¾Ğ³Ó£: {e}")
    finally:
        for p in [ogg_path, wav_path]:
            if os.path.exists(p): os.remove(p)
        await sent_msg.delete()

@dp.message(F.text)
async def handle_text(message: types.Message):
    # Ğ¢Ğ°Ñ€Ò·ÑƒĞ¼Ğ°Ğ¸ Ğ¼Ğ°Ñ‚Ğ½ Ğ½Ğ¸Ğ· Ğ±Ğ¾ Ğ¼Ğ°Ğ½Ñ‚Ğ¸Ò›Ğ¸ Ğ·Ğ°Ğ½Ò·Ğ¸Ñ€Ğ°Ğ²Ó£ (Ğ°Ğ³Ğ°Ñ€ Ñ„Ğ°ÑŠĞ¾Ğ» Ğ±Ğ¾ÑˆĞ°Ğ´)
    mode = user_modes.get(message.from_user.id, 'chain_tg_ru_en')
    try:
        if mode == 'chain_tg_ru_en':
            ru = GoogleTranslator(source='tg', target='ru').translate(message.text)
            en = GoogleTranslator(source='ru', target='en').translate(ru)
            await message.answer(f"ğŸ‡·ğŸ‡º Ğ ÑƒÑÓ£: {ru}\nğŸ‡¬ğŸ‡§ ĞĞ½Ğ³Ğ»Ğ¸ÑÓ£: {en}")
        else:
            src, dest = mode.split('_')
            res = GoogleTranslator(source=src, target=dest).translate(message.text)
            await message.answer(f"ğŸ“ Ğ¢Ğ°Ñ€Ò·ÑƒĞ¼Ğ°: {res}")
    except Exception as e:
        await message.answer(f"Ğ¥Ğ°Ñ‚Ğ¾: {e}")

async main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
